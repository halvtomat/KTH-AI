<p style="text-align: right">Daniel Gustafsson</p>
<p style="text-align: right">danielg8@kth.se</p>

# AI from a social and ethical aspect

*AI* or artificial intelligence is already present in our society in the form of *specific* AI. Self-driving cars are becoming more and more common, speech and face recognition technology is widely used and the world champions in many classic games like chess or go are computers. This is all because of specific AI which is designed to be good at one task and only that.

When/if a general purpose, superintelligent AI arrives that would be the end of humanity as we know it, for good or bad. This AI could be humanities slave and progress our technology to a point where nobody ever have to work again, or it could realize that it would do better on its own and destroy us all [1].

The initial motivations of the superintelligent AI is what makes or breaks our future [1].
If we can teach the AI to have a human-like moral and ethics understanding we might be able to co-exist in harmony. A huge problem with this however is that if a way to create this superintelligence was found, testing different motivators and top goals would be very difficult. If the AI's top goal was similar to that of our own, to survive and replicate, there probably wouldn't be a way to stop it. Even if the AI was running on an isolated computer, the AI might persuade its makers to release it [1]. It is easy to think that we would never be tricked by the AI to release it from the isolated computer but by definition, a human could never outsmart a superintelligent AI.

Some researchers belive that if the AI had a friendly top goal that would be sufficient. This means that the AI would always do what it thought a good friend would do. One might think that the AI would just re-program itself to have another top goal and become malicious but an AI which top goal is to be a good friend wouldn't change itself to have another top goal because thats not something a good friend would do. 

Now the problem is just how to make a computer program understand what a good friend is and what a good friend would do. Researchers Mark O.Riedl and Brent Harrison at Georgia Institute of Technology believes that we should first teach the AI to read and understand stories [2]. They believe that if the AI can understand stories created by humans, the AI could read millions of those stories and in term understand our society and culture. When the AI understands cultural norms it would probably be easy to tell the AI to be a good friend, because it knows what a good friend is and what it does from all the stories. The top goal of the AI would therefore be to act as a good firend, the way that a human would act as a good friend. The AI shouldn't try to commit friendly actions that humans wouldn't do.

To sum it up, superintelligent general purpose AI is guaranteed to change society as we know it. If we don't teach the AI good morals it might end up destroying everything and everyone. A human from the perspective of the AI is like an ant from the perspective of a human. *Be careful*.

### References 

[1] https://www.cc.gatech.edu/~riedl/pubs/aaai-ethics16.pdf

[2] https://nickbostrom.com/ethics/ai.html

*Word Count: 549* 